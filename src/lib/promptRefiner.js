import OpenAI from 'openai';
import { getConversationalRefinementSystemPrompt, getContinuationSystemPrompt } from '@/prompts/conversationalRefinementPrompt.js';

// ==================== API é…ç½®ä¸åˆå§‹åŒ– ====================
const PROXY_PATH = process.env.VUE_APP_API_PROXY_PATH;
const MODEL = process.env.VUE_APP_REFINEMENT_MODEL || 'gpt-4.1';

let refinementClient = null;
let initializationError = null;

try {
  if (!PROXY_PATH) {
    initializationError = 'Refinement API proxy path not configured correctly. Please check your environment variables.';
    console.warn(initializationError);
  } else {
    // åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒä¸­ï¼Œä½¿ç”¨ä»£ç†çš„åŸºç¡€URLï¼ˆä¸åŒ…å«/chat/completionsï¼‰
    const baseURL = window.location.origin;
    refinementClient = new OpenAI({
      apiKey: 'not-needed-for-proxy', // ä»»æ„å­—ç¬¦ä¸²
      baseURL: baseURL, // ä½¿ç”¨åŸºç¡€URLï¼Œè®©OpenAI SDKè‡ªåŠ¨æ·»åŠ è·¯å¾„
      dangerouslyAllowBrowser: true
    });
    console.log('Prompt Refinement API client initialized for proxy successfully');
  }
} catch (error) {
  initializationError = `Failed to initialize Prompt Refinement API client: ${error.message}`;
  console.error(initializationError, error);
  refinementClient = null;
}

/**
 * ç»Ÿä¸€å¤„ç† API é”™è¯¯ï¼ŒæŠ›å‡ºå¸¦ä¸Šä¸‹æ–‡çš„é”™è¯¯ä¿¡æ¯
 * @param {Error} error - é”™è¯¯å¯¹è±¡
 * @param {string} context - é”™è¯¯å‘ç”Ÿåœºæ™¯
 * @throws {Error}
 */
function handleApiError(error, context) {
  let message = `Failed during Refinement API call (${context}).`;
  if (error instanceof OpenAI.APIError) {
    message = `Refinement API Error (${context}): ${error.status} ${error.name} - ${error.message}`;
    if (error.error) {
        message += ` Details: ${JSON.stringify(error.error)}`;
    }
  } else if (error instanceof Error) {
    message = `Refinement Client Error (${context}): ${error.message}`;
  }
  throw new Error(message);
}

/**
 * æ ¡éªŒ Prompt å†…å®¹è´¨é‡ï¼Œè¿”å›ç»“æ„åŒ–å»ºè®®
 * @param {string} promptContent - å¾…æ ¡éªŒçš„ Prompt å†…å®¹
 * @returns {Promise<string>} æ ¡éªŒç»“æœï¼ˆMarkdown åˆ—è¡¨æˆ–é€šè¿‡æç¤ºï¼‰
 * @throws {Error}
 */
export async function validatePromptContent(promptContent) {
  if (!refinementClient) {
    const errorMessage = initializationError || 'Refinement client is not initialized. Cannot validate prompt.';
    throw new Error(errorMessage);
  }
  if (!promptContent || promptContent.trim() === '') {
    throw new Error('Promptå†…å®¹ä¸èƒ½ä¸ºç©º');
  }
  // æ„é€ ç³»ç»Ÿæç¤ºè¯ï¼Œè¦æ±‚ LLM ç»“æ„åŒ–æ ¡éªŒ
  const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Promptè´¨é‡æ£€æŸ¥å·¥ç¨‹å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å®¡æŸ¥ç”¨æˆ·æä¾›çš„ Promptï¼Œå¹¶æ ¹æ®ä»¥ä¸‹è§„åˆ™ç»™å‡ºç»“æ„åŒ–çš„é—®é¢˜åˆ—è¡¨å’Œå»ºè®®ã€‚

  **æ ¡éªŒè§„åˆ™ï¼š**
  1.  **ç»“æ„å®Œæ•´æ€§ (High Priority)ï¼š**
      *   Prompt æ˜¯å¦åŒ…å«ä»¥ä¸‹ä¸»è¦ç« èŠ‚ï¼š\`<summary_title>\`, \`<image_analysis>\`, \`<development_planning>\`ã€‚
      *   æ¯ä¸ªç« èŠ‚æ˜¯å¦è‡³å°‘åŒ…å«ä¸€äº›å†…å®¹ï¼Œè€Œä¸æ˜¯ç©ºç¼ºã€‚
  2.  **å†…å®¹å®Œæ•´æ€§ (Medium Priority)ï¼š**
      *   åœ¨ \`<image_analysis>\` ä¸­ï¼Œæ˜¯å¦è¯¦ç»†æè¿°äº† UI å…ƒç´ ï¼ˆæŒ‰é’®ã€è¾“å…¥æ¡†ã€è¡¨æ ¼ã€å¯¼èˆªç­‰ï¼‰ã€å¸ƒå±€ã€é¢œè‰²ã€å­—ä½“ã€äº¤äº’ç»†èŠ‚ç­‰ã€‚**ç‰¹åˆ«æ£€æŸ¥UIå…ƒç´ çš„æ–‡æœ¬ã€æ ‡ç­¾ã€å ä½ç¬¦æ˜¯å¦ä¿æŒäº†åŸå§‹è¯­è¨€ï¼Œæ²¡æœ‰è¢«ç¿»è¯‘ã€‚**
      *   åœ¨ \`<development_planning>\` ä¸­ï¼Œæ˜¯å¦æ˜ç¡®æåˆ°äº†ç»„ä»¶ä½¿ç”¨ç­–ç•¥ï¼ˆä¾‹å¦‚ï¼šä¼˜å…ˆä½¿ç”¨å†…éƒ¨åº“å’Œ Element UIï¼‰ã€ä¸»è¦åŠŸèƒ½å®ç°ã€API äº¤äº’ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ã€‚
      *   æ˜¯å¦æ˜ç¡®æåˆ°äº†é¡¹ç›®ä½¿ç”¨çš„æ¡†æ¶å’Œç»„ä»¶åº“ï¼ˆä¾‹å¦‚ä¸ºReactå»ºè®®Hooksï¼Œä¸ºVueå»ºè®®Composition APIï¼‰ã€‚
  3.  **å¯æ‰§è¡Œæ€§ä¸æ¸…æ™°åº¦ (Medium Priority)ï¼š**
      *   Prompt æ˜¯å¦è¶³å¤Ÿæ¸…æ™°å’Œå…·ä½“ï¼Œè®©ä¸€ä¸ªå‰ç«¯å¼€å‘è€…èƒ½ç›´æ¥å¼€å§‹å®ç°ï¼Œé¿å…æ¨¡ç³Šçš„æŒ‡ä»¤ã€‚
      *   ä»£ç å—æˆ–ç¤ºä¾‹æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆå¦‚æœåŒ…å«ï¼‰ã€‚
  4.  **å†—ä½™/å ä½ç¬¦æ£€æŸ¥ (Low Priority)ï¼š**
      *   æ˜¯å¦å­˜åœ¨ \`[è¯·å¡«å†™...]\`, \`[TODO]\`, \`[å¾…è¡¥å……]\` ç­‰æ˜æ˜¾çš„å ä½ç¬¦æˆ–æœªå®Œæˆçš„æŒ‡ç¤ºã€‚
      *   æ˜¯å¦å­˜åœ¨é‡å¤æˆ–å†—ä½™çš„ä¿¡æ¯ã€‚
  5.  **è¯­è¨€ä¸€è‡´æ€§ (Medium Priority)ï¼š**
      *   Prompt çš„ä¸»è¦è¯­è¨€æ˜¯å¦ä¸å›¾ç‰‡/ç”¨æˆ·æŒ‡ä»¤çš„è¯­è¨€ä¸€è‡´ã€‚
      *   **UIå…ƒç´ æ–‡æœ¬ä¿ç•™æ£€æŸ¥ (CRITICAL)ï¼š** æ£€æŸ¥Promptä¸­æè¿°çš„UIå…ƒç´ æ–‡æœ¬ï¼ˆæŒ‰é’®æ–‡å­—ã€è¾“å…¥æ¡†æ ‡ç­¾ã€å ä½ç¬¦ã€è¡¨æ ¼åˆ—å¤´ç­‰ï¼‰æ˜¯å¦ä¿æŒäº†åŸå§‹è¯­è¨€ï¼Œæ²¡æœ‰è¢«ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚ä¾‹å¦‚ï¼Œå¦‚æœåŸå›¾ä¸­æŒ‰é’®æ˜¾ç¤º"Settings"ï¼ŒPromptä¸­åº”è¯¥ä¿æŒ"Settings"è€Œä¸æ˜¯"è®¾ç½®".

  **è¾“å‡ºæ ¼å¼ï¼š**
  è¯·ä»¥ Markdown åˆ—è¡¨çš„å½¢å¼è¾“å‡ºæ ¡éªŒç»“æœã€‚å¦‚æœå‘ç°é—®é¢˜ï¼Œè¯·åœ¨æ¯ä¸ªé—®é¢˜å‰ä½¿ç”¨ \`ğŸš¨\` (é”™è¯¯), \`âš ï¸\` (è­¦å‘Š), \`ğŸ’¡\` (å»ºè®®) ç¬¦å·æ¥è¡¨ç¤ºå…¶ä¸¥é‡æ€§ã€‚
  ç¤ºä¾‹ï¼š
  - ğŸš¨ **ç»“æ„ç¼ºå¤±ï¼š** æœªæ‰¾åˆ° \`<image_analysis>\` ç« èŠ‚ã€‚
  - âš ï¸ **å†…å®¹ä¸è¶³ï¼š** \`<development_planning>\` ä¸­ç¼ºå°‘å…·ä½“çš„APIäº¤äº’è¯´æ˜ã€‚
  - ğŸ’¡ **ä¼˜åŒ–å»ºè®®ï¼š** è€ƒè™‘åœ¨ \`summary_title\` ä¸­å¢åŠ æ›´å¤šé¡µé¢çš„ä¸šåŠ¡ä¸Šä¸‹æ–‡ã€‚
  - âš ï¸ **å ä½ç¬¦ï¼š** Prompt ä¸­åŒ…å«æœªå¡«å……çš„ \`[è¯·å¡«å†™ä½ çš„å‰ç«¯æ¡†æ¶]\`ã€‚

  å¦‚æœPromptè´¨é‡å¾ˆé«˜ï¼Œæ²¡æœ‰å‘ç°æ˜æ˜¾é—®é¢˜ï¼Œè¯·å›å¤ "âœ… Prompt è´¨é‡ä¼˜ç§€ï¼Œæ²¡æœ‰å‘ç°ç»“æ„æˆ–å†…å®¹ä¸Šçš„æ˜æ˜¾é—®é¢˜ã€‚"`;
  const messages = [
    {
      "role": "system",
      "content": systemPrompt
    },
    {
      "role": "user",
      "content": `è¯·æ£€æŸ¥ä»¥ä¸‹ Promptï¼š\n\n\`\`\`\n${promptContent}\n\`\`\``
    }
  ];
  try {
    const response = await refinementClient.chat.completions.create({
      model: MODEL,
      messages: messages,
      temperature: 0.1,
      max_tokens: 1000,
    });
    return response.choices[0]?.message?.content || 'Prompt æ ¡éªŒå¤±è´¥æˆ–æ— å“åº”ã€‚';
  } catch (error) {
    handleApiError(error, 'prompt validation');
  }
}

/**
 * å¯¹è¯å¼ Prompt ä¼˜åŒ–ï¼Œæ”¯æŒå¤šè½®å†å²ã€å›¾ç‰‡ã€ç»­å†™
 * @param {string} currentFullPrompt - å½“å‰åŸºç¡€ Prompt
 * @param {Array} history - èŠå¤©å†å²ï¼ˆå«ç”¨æˆ·/åŠ©æ‰‹æ¶ˆæ¯ï¼‰
 * @param {string} userTextMessage - ç”¨æˆ·è¾“å…¥
 * @param {string|null} imageBase64 - å¯é€‰å›¾ç‰‡
 * @param {number} temperature - ç”Ÿæˆæ¸©åº¦
 * @param {string} framework - å‰ç«¯æ¡†æ¶
 * @param {string} componentLibrary - ç»„ä»¶åº“
 * @param {boolean} isContinuation - æ˜¯å¦ä¸ºç»­å†™
 * @returns {Promise<Stream<OpenAI.Chat.Completions.ChatCompletionChunk>>} æµå¼å“åº”
 * @throws {Error}
 */
export async function streamRefinement(
  currentFullPrompt,
  history,
  userTextMessage,
  imageBase64 = null,
  temperature = 0.2,
  framework = 'Vue',
  componentLibrary = 'ElementPlus',
  isContinuation = false
){
  if (!refinementClient) {
    throw new Error('Refinement client is not initialized. Cannot refine prompt.');
  }
  // æ„é€ ç”¨æˆ·æ¶ˆæ¯å†…å®¹
  const userMessageContent = [{ type: 'text', text: userTextMessage }];
  if (imageBase64) {
    userMessageContent.push({
      type: 'image_url',
      image_url: { url: imageBase64 },
    });
  }
  // é€‰æ‹©ç³»ç»Ÿæç¤ºè¯
  const systemPrompt = isContinuation
    ? getContinuationSystemPrompt()
    : getConversationalRefinementSystemPrompt(framework, componentLibrary, currentFullPrompt);
  // æ„é€ å†å²æ¶ˆæ¯
  const actualHistoryForApi = history.map(msg => {
    if (msg.role === 'user') {
      if (msg.type === 'dev-solution-input') {
        return { role: 'user', content: `[DEVELOPER_SOLUTION]: ${msg.text}` };
      } else if (msg.type === 'api-doc-input') {
        return { role: 'user', content: `[API_DOCUMENT]: ${msg.text}` };
      } else if (msg.imagePreview && msg.type === 'image-upload') {
        return { role: 'user', content: [{ type: 'text', text: msg.text || '' }, { type: 'image_url', image_url: { url: msg.imagePreview } }] };
      } else if (msg.documentName && msg.type === 'document-upload') {
        return { role: 'user', content: msg.text || `[ç”¨æˆ·ä¸Šä¼ äº†æ–‡æ¡£: ${msg.documentName}]` };
      }
      return { role: 'user', content: msg.text || '' };
    }
    return { role: 'assistant', content: msg.content };
  });
  const messages = [
    {
      role: 'system',
      content: systemPrompt,
    },
    ...actualHistoryForApi,
    {
      role: 'user',
      content: userMessageContent,
    },
  ];
  try {
    const stream = await refinementClient.chat.completions.create({
      model: MODEL,
      messages: messages,
      temperature: temperature,
      stream: true,
      max_tokens: 4000,
    });
    return stream;
  } catch (error) {
    handleApiError(error, 'refinement');
  }
}
